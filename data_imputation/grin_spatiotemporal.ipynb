{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:25:22.205041Z",
     "iopub.status.busy": "2025-04-09T05:25:22.204662Z",
     "iopub.status.idle": "2025-04-09T05:25:22.224025Z",
     "shell.execute_reply": "2025-04-09T05:25:22.222837Z",
     "shell.execute_reply.started": "2025-04-09T05:25:22.205015Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Bước 1: Kiểm tra và cài đặt thư viện (nếu cần)...\n",
      "Thư viện tsl đã được cài đặt.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "import os # Để tạo thư mục logs\n",
    "\n",
    "# --- Phần 1: Cài đặt thư viện và Imports ---\n",
    "print(\">>> Bước 1: Kiểm tra và cài đặt thư viện (nếu cần)...\")\n",
    "try:\n",
    "    from tsl.data import ImputationDataset, SpatioTemporalDataModule\n",
    "    from tsl.data.preprocessing import StandardScaler\n",
    "    from tsl.data.datamodule.splitters import TemporalSplitter\n",
    "    from tsl.nn.models import GRINModel\n",
    "    from tsl.metrics import numpy as numpy_metrics\n",
    "    from tsl.metrics import torch as torch_metrics\n",
    "    from tsl.engines import Imputer\n",
    "    from tsl.utils.casting import torch_to_numpy\n",
    "    print(\"Thư viện tsl đã được cài đặt.\")\n",
    "except ImportError:\n",
    "    print(\"Đang cài đặt thư viện tsl và các phụ thuộc...\")\n",
    "    # Lưu ý: Lệnh pip có thể cần điều chỉnh tùy thuộc môi trường (Colab, Kaggle, local)\n",
    "    # và phiên bản CUDA của bạn. Đây là ví dụ cho PyTorch 2.x và CUDA 12.1.\n",
    "    # Thay đổi '+cu121' nếu bạn dùng phiên bản CUDA khác hoặc CPU.\n",
    "    !pip install torch-scatter -f https://data.pyg.org/whl/torch-2.5.1+cu121.html\n",
    "    !pip install torch-sparse -f https://data.pyg.org/whl/torch-2.5.1+cu121.html\n",
    "    !pip install torch-geometric\n",
    "    !pip install torch-spatiotemporal\n",
    "    print(\"Cài đặt hoàn tất.\")\n",
    "    # Import lại sau khi cài đặt\n",
    "    from tsl.data import ImputationDataset, SpatioTemporalDataModule\n",
    "    from tsl.data.preprocessing import StandardScaler\n",
    "    from tsl.data.datamodule.splitters import TemporalSplitter\n",
    "    from tsl.nn.models import GRINModel\n",
    "    from tsl.metrics import numpy as numpy_metrics\n",
    "    from tsl.metrics import torch as torch_metrics\n",
    "    from tsl.engines import Imputer\n",
    "    from tsl.utils.casting import torch_to_numpy\n",
    "\n",
    "from torch.utils.data import DataLoader # Import DataLoader chuẩn\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:33:34.564887Z",
     "iopub.status.busy": "2025-04-09T05:33:34.564562Z",
     "iopub.status.idle": "2025-04-09T05:33:34.665807Z",
     "shell.execute_reply": "2025-04-09T05:33:34.665040Z",
     "shell.execute_reply.started": "2025-04-09T05:33:34.564864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "atmospheric_path = \"/kaggle/input/satellite-based-dataset/atmospheric_factors_df.csv\"\n",
    "atmospheric_factors_df = pd.read_csv(atmospheric_path)\n",
    "satellite_based_factors = ['CLOUD', 'CO', 'HCHO', 'NO2', 'O3', 'SO2', 'AAI']\n",
    "atmospheric_factors_df['date'] = pd.to_datetime(atmospheric_factors_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:33:59.809527Z",
     "iopub.status.busy": "2025-04-09T05:33:59.809084Z",
     "iopub.status.idle": "2025-04-09T05:33:59.819269Z",
     "shell.execute_reply": "2025-04-09T05:33:59.818254Z",
     "shell.execute_reply.started": "2025-04-09T05:33:59.809394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def convert_pivot_df(df: pd.DataFrame, factors=satellite_based_factors) -> pd.DataFrame:\n",
    "    \n",
    "    converted_df = df.melt(\n",
    "        id_vars=['date', 'ID'],\n",
    "        value_vars=factors,\n",
    "        var_name=\"satellite_based_factors\",\n",
    "        value_name=\"value\"\n",
    "    )\n",
    "    \n",
    "    pivot_df = converted_df.pivot_table(\n",
    "        index='date',\n",
    "        columns=['ID', \"satellite_based_factors\"],\n",
    "        values=\"value\",\n",
    "        fill_value=np.nan\n",
    "    )\n",
    "    \n",
    "    return pivot_df\n",
    "\n",
    "def calculate_adj_matrix(df: pd.DataFrame) -> tuple:\n",
    "    station_ids = df['ID'].unique()\n",
    "    coord_list = []\n",
    "\n",
    "    for id in station_ids:\n",
    "        id_coord = list(df.loc[df['ID'] == id][['lon', 'lat']].iloc[0])\n",
    "        coord_list.append(id_coord)\n",
    "\n",
    "    # Tính khoảng cách giữa các trạm\n",
    "    distances = cdist(coord_list, coord_list, metric=\"euclidean\")\n",
    "\n",
    "    # Thêm epsilon nhỏ để tránh chia cho 0\n",
    "    epsilon = 1e-10\n",
    "\n",
    "    # Trích xuất edge index\n",
    "    edge_index = np.array(np.nonzero(distances))\n",
    "\n",
    "    # Tính edge weight dựa trên nghịch đảo khoảng cách\n",
    "    edge_weight = 1.0 / (distances[edge_index[0], edge_index[1]] + epsilon)\n",
    "\n",
    "    # Chuẩn hóa theo từng node một cách an toàn\n",
    "    for i in range(len(station_ids)):\n",
    "        mask = (edge_index[0] == i)\n",
    "        if mask.sum() > 0:\n",
    "            weight_sum = edge_weight[mask].sum()\n",
    "            if weight_sum > epsilon:  # Tránh chia cho giá trị gần bằng 0\n",
    "                edge_weight[mask] = edge_weight[mask] / weight_sum\n",
    "\n",
    "    return edge_index, edge_weight.astype(np.float32)\n",
    "\n",
    "def calculate_mask_matrix(pivot_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return (~pivot_df.isna()).astype(bool)\n",
    "\n",
    "def calculate_covariates(pivot_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Sử dụng cả ngày và tháng làm đặc trưng phụ\n",
    "    day_features = pivot_df.index.day.values.reshape(-1, 1)\n",
    "    month_features = pivot_df.index.month.values.reshape(-1, 1)\n",
    "    return np.concatenate([day_features, month_features], axis=1)\n",
    "\n",
    "def create_balanced_eval_mask(pivot_df, ratio=0.4):\n",
    "    \"\"\"Tạo mask đánh giá cân bằng, chỉ sử dụng một phần dữ liệu không thiếu để đánh giá.\"\"\"\n",
    "\n",
    "    # Mask dữ liệu có sẵn\n",
    "    available_mask = ~pivot_df.isna()\n",
    "\n",
    "    # Tạo mask ngẫu nhiên với tỷ lệ ratio% dữ liệu có sẵn\n",
    "    np.random.seed(42)  # Đảm bảo tính tái lập\n",
    "    random_mask = np.random.rand(*available_mask.shape) < ratio\n",
    "\n",
    "    # Mask đánh giá chỉ bao gồm dữ liệu có sẵn\n",
    "    eval_mask = available_mask & random_mask\n",
    "\n",
    "    return eval_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:34:10.685138Z",
     "iopub.status.busy": "2025-04-09T05:34:10.684807Z",
     "iopub.status.idle": "2025-04-09T05:34:10.909860Z",
     "shell.execute_reply": "2025-04-09T05:34:10.908994Z",
     "shell.execute_reply.started": "2025-04-09T05:34:10.685111Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng giá trị có sẵn: 248005\n",
      "Số lượng giá trị dùng cho đánh giá: 49442\n",
      "Tỷ lệ đánh giá/có sẵn: 0.20\n"
     ]
    }
   ],
   "source": [
    "# Tạo pivot_df, adj và các mặt nạ\n",
    "pivot_df = convert_pivot_df(df=atmospheric_factors_df)\n",
    "adj = calculate_adj_matrix(df=atmospheric_factors_df)\n",
    "covariates = calculate_covariates(pivot_df)\n",
    "mask_matrix = calculate_mask_matrix(pivot_df)\n",
    "eval_mask = create_balanced_eval_mask(pivot_df, ratio=0.2)\n",
    "\n",
    "# Kiểm tra thông tin mask\n",
    "print(f\"Số lượng giá trị có sẵn: {mask_matrix.sum().sum()}\")\n",
    "print(f\"Số lượng giá trị dùng cho đánh giá: {eval_mask.sum().sum()}\")\n",
    "print(f\"Tỷ lệ đánh giá/có sẵn: {eval_mask.sum().sum() / mask_matrix.sum().sum():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:34:17.312546Z",
     "iopub.status.busy": "2025-04-09T05:34:17.312211Z",
     "iopub.status.idle": "2025-04-09T05:34:17.777423Z",
     "shell.execute_reply": "2025-04-09T05:34:17.776445Z",
     "shell.execute_reply.started": "2025-04-09T05:34:17.312519Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cột (5, 'AAI'): 58 outlier được phát hiện\n",
      "Cột (5, 'CO'): 41 outlier được phát hiện\n",
      "Cột (5, 'HCHO'): 18 outlier được phát hiện\n",
      "Cột (5, 'NO2'): 33 outlier được phát hiện\n",
      "Cột (5, 'SO2'): 22 outlier được phát hiện\n",
      "Cột (19, 'AAI'): 48 outlier được phát hiện\n",
      "Cột (19, 'CO'): 32 outlier được phát hiện\n",
      "Cột (19, 'HCHO'): 19 outlier được phát hiện\n",
      "Cột (19, 'NO2'): 47 outlier được phát hiện\n",
      "Cột (19, 'O3'): 1 outlier được phát hiện\n",
      "Cột (19, 'SO2'): 24 outlier được phát hiện\n",
      "Cột (51, 'AAI'): 55 outlier được phát hiện\n",
      "Cột (51, 'CO'): 48 outlier được phát hiện\n",
      "Cột (51, 'HCHO'): 18 outlier được phát hiện\n",
      "Cột (51, 'NO2'): 32 outlier được phát hiện\n",
      "Cột (51, 'SO2'): 28 outlier được phát hiện\n",
      "Cột (52, 'AAI'): 61 outlier được phát hiện\n",
      "Cột (52, 'CO'): 35 outlier được phát hiện\n",
      "Cột (52, 'HCHO'): 19 outlier được phát hiện\n",
      "Cột (52, 'NO2'): 63 outlier được phát hiện\n",
      "Cột (52, 'SO2'): 24 outlier được phát hiện\n",
      "Cột (53, 'AAI'): 62 outlier được phát hiện\n",
      "Cột (53, 'CO'): 43 outlier được phát hiện\n",
      "Cột (53, 'HCHO'): 25 outlier được phát hiện\n",
      "Cột (53, 'NO2'): 43 outlier được phát hiện\n",
      "Cột (53, 'SO2'): 42 outlier được phát hiện\n",
      "Cột (54, 'AAI'): 64 outlier được phát hiện\n",
      "Cột (54, 'CO'): 37 outlier được phát hiện\n",
      "Cột (54, 'HCHO'): 21 outlier được phát hiện\n",
      "Cột (54, 'NO2'): 51 outlier được phát hiện\n",
      "Cột (54, 'SO2'): 18 outlier được phát hiện\n",
      "Cột (60, 'AAI'): 57 outlier được phát hiện\n",
      "Cột (60, 'CO'): 49 outlier được phát hiện\n",
      "Cột (60, 'HCHO'): 21 outlier được phát hiện\n",
      "Cột (60, 'NO2'): 46 outlier được phát hiện\n",
      "Cột (60, 'SO2'): 32 outlier được phát hiện\n",
      "Cột (62, 'AAI'): 66 outlier được phát hiện\n",
      "Cột (62, 'CO'): 41 outlier được phát hiện\n",
      "Cột (62, 'HCHO'): 24 outlier được phát hiện\n",
      "Cột (62, 'NO2'): 56 outlier được phát hiện\n",
      "Cột (62, 'SO2'): 45 outlier được phát hiện\n",
      "Cột (66, 'AAI'): 57 outlier được phát hiện\n",
      "Cột (66, 'CO'): 46 outlier được phát hiện\n",
      "Cột (66, 'HCHO'): 21 outlier được phát hiện\n",
      "Cột (66, 'NO2'): 39 outlier được phát hiện\n",
      "Cột (66, 'SO2'): 25 outlier được phát hiện\n",
      "Cột (71, 'AAI'): 56 outlier được phát hiện\n",
      "Cột (71, 'CO'): 37 outlier được phát hiện\n",
      "Cột (71, 'HCHO'): 24 outlier được phát hiện\n",
      "Cột (71, 'NO2'): 43 outlier được phát hiện\n",
      "Cột (71, 'SO2'): 32 outlier được phát hiện\n",
      "Cột (79, 'AAI'): 53 outlier được phát hiện\n",
      "Cột (79, 'CO'): 29 outlier được phát hiện\n",
      "Cột (79, 'HCHO'): 8 outlier được phát hiện\n",
      "Cột (79, 'NO2'): 27 outlier được phát hiện\n",
      "Cột (79, 'SO2'): 29 outlier được phát hiện\n",
      "Cột (155, 'AAI'): 58 outlier được phát hiện\n",
      "Cột (155, 'CO'): 46 outlier được phát hiện\n",
      "Cột (155, 'HCHO'): 28 outlier được phát hiện\n",
      "Cột (155, 'NO2'): 40 outlier được phát hiện\n",
      "Cột (155, 'SO2'): 32 outlier được phát hiện\n",
      "Cột (156, 'AAI'): 56 outlier được phát hiện\n",
      "Cột (156, 'CO'): 42 outlier được phát hiện\n",
      "Cột (156, 'HCHO'): 20 outlier được phát hiện\n",
      "Cột (156, 'NO2'): 32 outlier được phát hiện\n",
      "Cột (156, 'SO2'): 29 outlier được phát hiện\n",
      "Cột (157, 'AAI'): 54 outlier được phát hiện\n",
      "Cột (157, 'CO'): 41 outlier được phát hiện\n",
      "Cột (157, 'HCHO'): 15 outlier được phát hiện\n",
      "Cột (157, 'NO2'): 36 outlier được phát hiện\n",
      "Cột (157, 'SO2'): 29 outlier được phát hiện\n",
      "Cột (158, 'AAI'): 65 outlier được phát hiện\n",
      "Cột (158, 'CO'): 33 outlier được phát hiện\n",
      "Cột (158, 'HCHO'): 29 outlier được phát hiện\n",
      "Cột (158, 'NO2'): 59 outlier được phát hiện\n",
      "Cột (158, 'SO2'): 32 outlier được phát hiện\n",
      "Cột (159, 'AAI'): 60 outlier được phát hiện\n",
      "Cột (159, 'CO'): 41 outlier được phát hiện\n",
      "Cột (159, 'HCHO'): 20 outlier được phát hiện\n",
      "Cột (159, 'NO2'): 58 outlier được phát hiện\n",
      "Cột (159, 'SO2'): 29 outlier được phát hiện\n",
      "Cột (160, 'AAI'): 58 outlier được phát hiện\n",
      "Cột (160, 'CO'): 36 outlier được phát hiện\n",
      "Cột (160, 'HCHO'): 31 outlier được phát hiện\n",
      "Cột (160, 'NO2'): 53 outlier được phát hiện\n",
      "Cột (160, 'SO2'): 36 outlier được phát hiện\n",
      "Cột (161, 'AAI'): 57 outlier được phát hiện\n",
      "Cột (161, 'CO'): 43 outlier được phát hiện\n",
      "Cột (161, 'HCHO'): 25 outlier được phát hiện\n",
      "Cột (161, 'NO2'): 31 outlier được phát hiện\n",
      "Cột (161, 'SO2'): 29 outlier được phát hiện\n",
      "Cột (162, 'AAI'): 57 outlier được phát hiện\n",
      "Cột (162, 'CO'): 41 outlier được phát hiện\n",
      "Cột (162, 'HCHO'): 23 outlier được phát hiện\n",
      "Cột (162, 'NO2'): 37 outlier được phát hiện\n",
      "Cột (162, 'SO2'): 31 outlier được phát hiện\n",
      "Cột (163, 'AAI'): 56 outlier được phát hiện\n",
      "Cột (163, 'CO'): 36 outlier được phát hiện\n",
      "Cột (163, 'HCHO'): 20 outlier được phát hiện\n",
      "Cột (163, 'NO2'): 35 outlier được phát hiện\n",
      "Cột (163, 'SO2'): 22 outlier được phát hiện\n",
      "Cột (169, 'AAI'): 64 outlier được phát hiện\n",
      "Cột (169, 'CO'): 35 outlier được phát hiện\n",
      "Cột (169, 'HCHO'): 18 outlier được phát hiện\n",
      "Cột (169, 'NO2'): 56 outlier được phát hiện\n",
      "Cột (169, 'SO2'): 20 outlier được phát hiện\n",
      "Cột (172, 'AAI'): 60 outlier được phát hiện\n",
      "Cột (172, 'CO'): 39 outlier được phát hiện\n",
      "Cột (172, 'HCHO'): 16 outlier được phát hiện\n",
      "Cột (172, 'NO2'): 54 outlier được phát hiện\n",
      "Cột (172, 'SO2'): 25 outlier được phát hiện\n",
      "Cột (173, 'AAI'): 60 outlier được phát hiện\n",
      "Cột (173, 'CO'): 37 outlier được phát hiện\n",
      "Cột (173, 'HCHO'): 17 outlier được phát hiện\n",
      "Cột (173, 'NO2'): 48 outlier được phát hiện\n",
      "Cột (173, 'SO2'): 23 outlier được phát hiện\n",
      "Cột (175, 'AAI'): 59 outlier được phát hiện\n",
      "Cột (175, 'CO'): 35 outlier được phát hiện\n",
      "Cột (175, 'HCHO'): 15 outlier được phát hiện\n",
      "Cột (175, 'NO2'): 52 outlier được phát hiện\n",
      "Cột (175, 'SO2'): 21 outlier được phát hiện\n",
      "Cột (195, 'AAI'): 58 outlier được phát hiện\n",
      "Cột (195, 'CO'): 54 outlier được phát hiện\n",
      "Cột (195, 'HCHO'): 15 outlier được phát hiện\n",
      "Cột (195, 'NO2'): 35 outlier được phát hiện\n",
      "Cột (195, 'O3'): 2 outlier được phát hiện\n",
      "Cột (195, 'SO2'): 32 outlier được phát hiện\n",
      "Cột (300, 'AAI'): 58 outlier được phát hiện\n",
      "Cột (300, 'CO'): 41 outlier được phát hiện\n",
      "Cột (300, 'HCHO'): 18 outlier được phát hiện\n",
      "Cột (300, 'NO2'): 33 outlier được phát hiện\n",
      "Cột (300, 'SO2'): 22 outlier được phát hiện\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra các cột có phương sai bằng 0\n",
    "variances = pivot_df.var()\n",
    "zero_variance_cols = variances[variances == 0].index\n",
    "if not zero_variance_cols.empty:\n",
    "    print(f\"Cảnh báo: Có cột có phương sai bằng 0: {zero_variance_cols}\")\n",
    "    print(\"Thêm nhiễu nhỏ để tăng phương sai...\")\n",
    "\n",
    "    # Thêm nhiễu nhỏ vào cột có phương sai bằng 0\n",
    "    for col in zero_variance_cols:\n",
    "        mask = ~pivot_df[col].isna()\n",
    "        if mask.sum() > 0:\n",
    "            # Thêm nhiễu nhỏ vào giá trị không phải NaN\n",
    "            mean_val = pivot_df.loc[mask, col].mean()\n",
    "            pivot_df.loc[mask, col] += np.random.normal(0, 0.001, size=mask.sum())\n",
    "\n",
    "# Kiểm tra giá trị outlier\n",
    "for col in pivot_df.columns:\n",
    "    values = pivot_df[col].dropna()\n",
    "    if len(values) > 0:\n",
    "        q1, q3 = values.quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "        # Đếm outlier\n",
    "        outliers = values[(values < lower_bound) | (values > upper_bound)]\n",
    "        if len(outliers) > 0:\n",
    "            print(f\"Cột {col}: {len(outliers)} outlier được phát hiện\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:34:23.430608Z",
     "iopub.status.busy": "2025-04-09T05:34:23.430245Z",
     "iopub.status.idle": "2025-04-09T05:34:23.440853Z",
     "shell.execute_reply": "2025-04-09T05:34:23.439826Z",
     "shell.execute_reply.started": "2025-04-09T05:34:23.430578Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tạo dataset dùng cho imputation\n",
    "imputation_dataset = ImputationDataset(\n",
    "    target=pivot_df,\n",
    "    eval_mask=eval_mask,  # Sử dụng mask được cân bằng\n",
    "    covariates={'time': covariates},  # Thêm đặc trưng thời gian\n",
    "    connectivity=adj,  # Sử dụng ma trận kề cải tiến\n",
    "    window=14,  # Giảm kích thước cửa sổ xuống\n",
    "    stride=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:34:28.052259Z",
     "iopub.status.busy": "2025-04-09T05:34:28.051943Z",
     "iopub.status.idle": "2025-04-09T05:34:28.078841Z",
     "shell.execute_reply": "2025-04-09T05:34:28.078032Z",
     "shell.execute_reply.started": "2025-04-09T05:34:28.052235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cấu hình datamodule với scale dữ liệu robust\n",
    "scalers = {'target': StandardScaler(axis=(0, 1))}\n",
    "\n",
    "splitter = TemporalSplitter(\n",
    "    val_len=0.1,\n",
    "    test_len=0.2\n",
    ")\n",
    "\n",
    "dm = SpatioTemporalDataModule(\n",
    "    dataset=imputation_dataset,\n",
    "    scalers=scalers,\n",
    "    splitter=splitter,\n",
    "    batch_size=64,  # Giảm kích thước batch để ổn định hơn\n",
    "    workers=4\n",
    ")\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:34:31.169922Z",
     "iopub.status.busy": "2025-04-09T05:34:31.169563Z",
     "iopub.status.idle": "2025-04-09T05:34:31.436324Z",
     "shell.execute_reply": "2025-04-09T05:34:31.435299Z",
     "shell.execute_reply.started": "2025-04-09T05:34:31.169889Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch có 64 mẫu, số lượng giá trị True trong val_eval_mask: 22325\n",
      "Batch có 64 mẫu, số lượng giá trị True trong val_eval_mask: 21409\n",
      "Batch có 31 mẫu, số lượng giá trị True trong val_eval_mask: 11010\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra eval_mask trên batch từ val_dataloader\n",
    "val_dataloader = dm.val_dataloader()\n",
    "for batch in val_dataloader:\n",
    "    val_eval_mask = batch['eval_mask']\n",
    "    num_samples = val_eval_mask.shape[0]  # Số mẫu trong batch\n",
    "    num_true = val_eval_mask.sum().item()\n",
    "    print(f\"Batch có {num_samples} mẫu, số lượng giá trị True trong val_eval_mask: {num_true}\")\n",
    "\n",
    "    # Kiểm tra nếu có quá ít giá trị True\n",
    "    if num_true < 10:\n",
    "        print(\"CẢNH BÁO: Quá ít điểm đánh giá trong batch!\")\n",
    "    # break  # Chỉ kiểm tra batch đầu tiên"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:34:37.773087Z",
     "iopub.status.busy": "2025-04-09T05:34:37.772721Z",
     "iopub.status.idle": "2025-04-09T05:34:37.784451Z",
     "shell.execute_reply": "2025-04-09T05:34:37.783572Z",
     "shell.execute_reply.started": "2025-04-09T05:34:37.773059Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_cls = GRINModel\n",
    "model_kwargs = dict(\n",
    "    n_nodes=imputation_dataset.n_nodes,\n",
    "    input_size=imputation_dataset.n_channels,\n",
    "    hidden_size=64,        # Tăng kích thước hidden để bắt xu hướng phức tạp\n",
    "    ff_size=128,           # Tăng feedforward size\n",
    "    embedding_size=8,      # Tăng kích thước embedding\n",
    "    n_layers=2,            # Thêm một lớp để tăng khả năng học\n",
    "    kernel_size=2,\n",
    "    decoder_order=1,\n",
    "    layer_norm=True,\n",
    "    dropout=0.1,           # Điều chỉnh dropout phù hợp\n",
    "    ff_dropout=0.1,\n",
    "    merge_mode='mlp'\n",
    ")\n",
    "\n",
    "loss_fn = torch_metrics.MaskedMAE()\n",
    "\n",
    "log_metrics = {\n",
    "    'mae': torch_metrics.MaskedMAE(),\n",
    "    'mse': torch_metrics.MaskedMSE(),\n",
    "    'mre': torch_metrics.MaskedMRE(),\n",
    "    'mape': torch_metrics.MaskedMAPE()\n",
    "}\n",
    "\n",
    "scheduler_class = torch.optim.lr_scheduler.CosineAnnealingLR\n",
    "epochs = 40  # Giảm số epoch\n",
    "scheduler_kwargs = dict(\n",
    "    eta_min=0.0001,\n",
    "    T_max=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:34:41.141168Z",
     "iopub.status.busy": "2025-04-09T05:34:41.140787Z",
     "iopub.status.idle": "2025-04-09T05:34:41.174455Z",
     "shell.execute_reply": "2025-04-09T05:34:41.173488Z",
     "shell.execute_reply.started": "2025-04-09T05:34:41.141122Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "imputer = Imputer(\n",
    "    model_class=model_cls,\n",
    "    model_kwargs=model_kwargs,\n",
    "    optim_class=torch.optim.Adam,\n",
    "    optim_kwargs={\n",
    "        \"lr\": 0.0005,          # Giảm learning rate\n",
    "        \"weight_decay\": 1e-4    # Tăng weight decay\n",
    "    },\n",
    "    loss_fn=loss_fn,\n",
    "    metrics=log_metrics,\n",
    "    scheduler_class=scheduler_class,\n",
    "    scheduler_kwargs=scheduler_kwargs,\n",
    "    scale_target=True,\n",
    "    whiten_prob=0.1,          # Tăng whiten_prob\n",
    "    prediction_loss_weight=1.0,\n",
    "    impute_only_missing=True,\n",
    "    warm_up_steps=10           # Thêm warm up steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:34:46.076561Z",
     "iopub.status.busy": "2025-04-09T05:34:46.076185Z",
     "iopub.status.idle": "2025-04-09T05:34:46.082524Z",
     "shell.execute_reply": "2025-04-09T05:34:46.081746Z",
     "shell.execute_reply.started": "2025-04-09T05:34:46.076530Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(save_dir=\"logs\", name=\"imputation\")\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_mae\", patience=5, mode=\"min\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"logs/imputation\",  # Sửa thành logs thay vì log\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_mae\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "callbacks = [early_stop_callback, checkpoint_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T05:34:49.413855Z",
     "iopub.status.busy": "2025-04-09T05:34:49.413457Z",
     "iopub.status.idle": "2025-04-09T06:19:07.332546Z",
     "shell.execute_reply": "2025-04-09T06:19:07.331677Z",
     "shell.execute_reply.started": "2025-04-09T05:34:49.413826Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /kaggle/working/logs/imputation exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (24) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd232b0fb7b47ac89e06824cafdf7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=epochs,\n",
    "    logger=logger,\n",
    "    callbacks=callbacks,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    gradient_clip_val=1.0,  # Giảm grad clip để tránh exploding gradients\n",
    "    enable_progress_bar=True,\n",
    "    detect_anomaly=True,    # Bật phát hiện anomaly để debug\n",
    "    check_val_every_n_epoch=1\n",
    ")\n",
    "\n",
    "trainer.fit(imputer, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T08:29:52.647768Z",
     "iopub.status.busy": "2025-04-09T08:29:52.647381Z",
     "iopub.status.idle": "2025-04-09T08:29:54.069436Z",
     "shell.execute_reply": "2025-04-09T08:29:54.068412Z",
     "shell.execute_reply.started": "2025-04-09T08:29:52.647738Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tsl/engines/predictor.py:121: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  storage = torch.load(filename, lambda storage, loc: storage)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d13b51c15840a59522b3ee7476417a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            0.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mae          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.06734113395214081    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mape         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      17754.384765625      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mre          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7071393728256226     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.023068714886903763    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           0.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mae         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.06734113395214081   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mape        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     17754.384765625     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mre         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7071393728256226    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.023068714886903763   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_mae': 0.06734113395214081,\n",
       "  'test_mape': 17754.384765625,\n",
       "  'test_mre': 0.7071393728256226,\n",
       "  'test_mse': 0.023068714886903763,\n",
       "  'test_loss': 0.0}]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.load_model(checkpoint_callback.best_model_path)\n",
    "imputer.freeze()\n",
    "trainer.test(imputer, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T08:29:59.552043Z",
     "iopub.status.busy": "2025-04-09T08:29:59.551728Z",
     "iopub.status.idle": "2025-04-09T08:29:59.591393Z",
     "shell.execute_reply": "2025-04-09T08:29:59.590538Z",
     "shell.execute_reply.started": "2025-04-09T08:29:59.552018Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tạo empty eval mask cho toàn bộ dataset\n",
    "def create_empty_eval_mask(pivot_df):\n",
    "    \"\"\"Tạo mask đánh giá rỗng (toàn False) có cùng định dạng với dữ liệu gốc.\"\"\"\n",
    "    eval_mask = pivot_df.isna().astype(int)\n",
    "    eval_mask = (eval_mask * 0).astype(bool)\n",
    "    return eval_mask\n",
    "\n",
    "# Tạo dataset mới để impute toàn bộ dữ liệu\n",
    "imputation_dataset_full = ImputationDataset(\n",
    "    target=pivot_df,  # Toàn bộ dữ liệu\n",
    "    eval_mask=create_empty_eval_mask(pivot_df),  # Không cần eval_mask\n",
    "    covariates={'time': covariates},  # Sử dụng covariates đã tạo trước đó\n",
    "    connectivity=adj,  # Sử dụng ma trận kề đã tạo trước đó\n",
    "    window=14,\n",
    "    stride=1\n",
    ")\n",
    "\n",
    "# Cấu hình datamodule cho toàn bộ dữ liệu\n",
    "dm_full = SpatioTemporalDataModule(\n",
    "    dataset=imputation_dataset_full,\n",
    "    scalers=scalers,  # Sử dụng cùng scaler đã dùng trong huấn luyện\n",
    "    splitter=None,  # Không cần chia dữ liệu\n",
    "    batch_size=64,\n",
    "    workers=4\n",
    ")\n",
    "dm_full.setup()\n",
    "\n",
    "# Tạo DataLoader cho toàn bộ dữ liệu\n",
    "dm_full.trainset = list(range(len(imputation_dataset_full)))\n",
    "full_dataloader = dm_full.train_dataloader(shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T08:30:08.239023Z",
     "iopub.status.busy": "2025-04-09T08:30:08.238716Z",
     "iopub.status.idle": "2025-04-09T08:30:08.245057Z",
     "shell.execute_reply": "2025-04-09T08:30:08.244083Z",
     "shell.execute_reply.started": "2025-04-09T08:30:08.239000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tạo hàm wrapper cho tsl.data.batch.StaticBatch để xử lý lỗi tensor shape khi predict\n",
    "from tsl.data.batch import StaticBatch\n",
    "\n",
    "def create_compatible_batch(batch_dict):\n",
    "    \"\"\"Chuyển đổi dictionary batch thành đối tượng StaticBatch.\"\"\"\n",
    "    batch = StaticBatch()\n",
    "    \n",
    "    # Tạo thuộc tính input\n",
    "    batch.input = type('InputContainer', (), {})()\n",
    "    \n",
    "    # Thêm các tensor cơ bản\n",
    "    batch.input.x = batch_dict['x']\n",
    "    batch.input.mask = batch_dict['mask']\n",
    "    \n",
    "    # Thêm các tensor tùy chọn\n",
    "    if 'edge_index' in batch_dict:\n",
    "        batch.input.edge_index = batch_dict['edge_index']\n",
    "    if 'edge_weight' in batch_dict:\n",
    "        batch.input.edge_weight = batch_dict['edge_weight']\n",
    "    if 'u' in batch_dict:\n",
    "        batch.input.u = batch_dict['u']\n",
    "    \n",
    "    # Thêm các thuộc tính khác\n",
    "    if 'y' in batch_dict:\n",
    "        batch.y = batch_dict['y']\n",
    "    batch.mask = batch_dict['mask']\n",
    "    if 'eval_mask' in batch_dict:\n",
    "        batch.eval_mask = batch_dict['eval_mask']\n",
    "    if 'transform' in batch_dict:\n",
    "        batch.transform = batch_dict['transform']\n",
    "    else:\n",
    "        batch.transform = {}\n",
    "    \n",
    "    # Thiết lập kích thước batch\n",
    "    batch.batch_size = batch_dict['x'].size(0)\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T08:30:11.351184Z",
     "iopub.status.busy": "2025-04-09T08:30:11.350891Z",
     "iopub.status.idle": "2025-04-09T08:30:11.362401Z",
     "shell.execute_reply": "2025-04-09T08:30:11.361354Z",
     "shell.execute_reply.started": "2025-04-09T08:30:11.351162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hàm dự đoán an toàn để xử lý các vấn đề kích thước tensor\n",
    "def safe_predict(imputer_model, dataloader, device):\n",
    "    \"\"\"Dự đoán an toàn trên từng mẫu một.\"\"\"\n",
    "    imputer_model.eval()  # Đặt mô hình về chế độ đánh giá\n",
    "    results = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            # Chuyển đổi sang StaticBatch tương thích\n",
    "            compatible_batch = create_compatible_batch(batch)\n",
    "            \n",
    "            try:\n",
    "                # Sử dụng predict_step để xử lý toàn bộ batch\n",
    "                output = imputer_model.predict_step(compatible_batch, batch_idx)\n",
    "                results.append(output)\n",
    "                \n",
    "                # In tiến trình\n",
    "                if (batch_idx + 1) % 5 == 0:\n",
    "                    print(f\"Đã xử lý {batch_idx + 1}/{len(dataloader)} batch\")\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi khi xử lý batch {batch_idx}: {e}\")\n",
    "                # Xử lý từng mẫu nếu xử lý cả batch gặp lỗi\n",
    "                batch_results = []\n",
    "                \n",
    "                # Chuyển dữ liệu sang device\n",
    "                x = batch['x'].to(device)\n",
    "                mask = batch['mask'].to(device)\n",
    "                edge_index = batch.get('edge_index', None)\n",
    "                if edge_index is not None:\n",
    "                    edge_index = edge_index.to(device)\n",
    "                edge_weight = batch.get('edge_weight', None)\n",
    "                if edge_weight is not None:\n",
    "                    edge_weight = edge_weight.to(device)\n",
    "                u = batch.get('u', None)\n",
    "                if u is not None:\n",
    "                    u = u.to(device)\n",
    "                    \n",
    "                # Xử lý từng mẫu\n",
    "                for i in range(x.size(0)):\n",
    "                    sample_x = x[i:i+1]  # Giữ batch dimension\n",
    "                    sample_mask = mask[i:i+1]\n",
    "                    sample_u = u[i:i+1] if u is not None else None\n",
    "                    \n",
    "                    # Chuẩn bị đầu vào\n",
    "                    input_dict = {\n",
    "                        'x': sample_x,\n",
    "                        'mask': sample_mask\n",
    "                    }\n",
    "                    if edge_index is not None:\n",
    "                        input_dict['edge_index'] = edge_index\n",
    "                    if edge_weight is not None:\n",
    "                        input_dict['edge_weight'] = edge_weight\n",
    "                    if sample_u is not None:\n",
    "                        input_dict['u'] = sample_u\n",
    "                        \n",
    "                    try:\n",
    "                        # Gọi forward và lấy kết quả\n",
    "                        output = imputer_model.model.forward(**input_dict)\n",
    "                        if isinstance(output, list) and len(output) > 0:\n",
    "                            imputation = output[0]\n",
    "                        else:\n",
    "                            imputation = output\n",
    "                            \n",
    "                        # Xử lý inverse transform\n",
    "                        trans = batch.get('transform', {}).get('y')\n",
    "                        if trans is not None:\n",
    "                            imputation = trans.inverse_transform(imputation)\n",
    "                            \n",
    "                        batch_results.append(imputation)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Lỗi khi dự đoán mẫu {i} trong batch {batch_idx}: {e}\")\n",
    "                        \n",
    "                # Kết hợp kết quả của batch\n",
    "                if batch_results:\n",
    "                    batch_imputation = torch.cat(batch_results, dim=0)\n",
    "                    \n",
    "                    batch_output = {\n",
    "                        'y': batch.get('y', torch.zeros_like(batch_imputation)).cpu(),\n",
    "                        'y_hat': batch_imputation.cpu(),\n",
    "                        'mask': batch['mask'].cpu(),\n",
    "                        'eval_mask': batch.get('eval_mask', torch.zeros_like(batch['mask'])).cpu()\n",
    "                    }\n",
    "                    \n",
    "                    results.append(batch_output)\n",
    "                    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T09:03:03.325594Z",
     "iopub.status.busy": "2025-04-09T09:03:03.325242Z",
     "iopub.status.idle": "2025-04-09T09:04:02.819858Z",
     "shell.execute_reply": "2025-04-09T09:04:02.818654Z",
     "shell.execute_reply.started": "2025-04-09T09:03:03.325568Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thực hiện imputation cho những điểm missing thực sự trong dữ liệu...\n",
      "\n",
      "Phương pháp 1: Sử dụng trainer.predict()...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4651869cee4a3fa36a2f87cfb6335e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã dự đoán thành công với 2112 batch\n",
      "\n",
      "Phương pháp 2: Sử dụng trainer.test()...\n",
      "Lỗi khi sử dụng trainer.test(): An invalid dataloader was returned from `SpatioTemporalDataModule.test_dataloader()`. Found None.\n",
      "\n",
      "Phương pháp 3: Sử dụng safe_predict()...\n",
      "Đã xử lý 5/33 batch\n",
      "Đã xử lý 10/33 batch\n",
      "Đã xử lý 15/33 batch\n",
      "Đã xử lý 20/33 batch\n",
      "Đã xử lý 25/33 batch\n",
      "Đã xử lý 30/33 batch\n",
      "Đã dự đoán thành công với 33 batch\n"
     ]
    }
   ],
   "source": [
    "# Thực hiện dự đoán trên toàn bộ dữ liệu\n",
    "print(\"Thực hiện imputation cho những điểm missing thực sự trong dữ liệu...\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Phương pháp 1: Sử dụng trainer.predict (đơn giản nhất nhưng có thể gặp lỗi tensor shape)\n",
    "try:\n",
    "    print(\"\\nPhương pháp 1: Sử dụng trainer.predict()...\")\n",
    "    predictions1 = trainer.predict(imputer, dataloaders=full_dataloader)\n",
    "    print(f\"Đã dự đoán thành công với {len(predictions)} batch\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi sử dụng trainer.predict(): {e}\")\n",
    "    predictions = None\n",
    "\n",
    "# Phương pháp 2: Sử dụng trainer.test (thường hoạt động tốt hơn)\n",
    "try:\n",
    "    print(\"\\nPhương pháp 2: Sử dụng trainer.test()...\")\n",
    "    test_results = trainer.test(imputer, datamodule=dm_full)\n",
    "    print(f\"Test metrics: {test_results}\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi khi sử dụng trainer.test(): {e}\")\n",
    "\n",
    "# Phương pháp 3: Sử dụng hàm safe_predict (đáng tin cậy nhất)\n",
    "print(\"\\nPhương pháp 3: Sử dụng safe_predict()...\")\n",
    "predictions = safe_predict(imputer, full_dataloader, device)\n",
    "print(f\"Đã dự đoán thành công với {len(predictions)} batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T09:15:46.223782Z",
     "iopub.status.busy": "2025-04-09T09:15:46.223441Z",
     "iopub.status.idle": "2025-04-09T09:15:46.231211Z",
     "shell.execute_reply": "2025-04-09T09:15:46.230486Z",
     "shell.execute_reply.started": "2025-04-09T09:15:46.223755Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "method1_output = imputer.collate_prediction_outputs(predictions)\n",
    "method1_output = torch_to_numpy(method1_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T09:15:51.927825Z",
     "iopub.status.busy": "2025-04-09T09:15:51.927439Z",
     "iopub.status.idle": "2025-04-09T09:15:51.935235Z",
     "shell.execute_reply": "2025-04-09T09:15:51.934403Z",
     "shell.execute_reply.started": "2025-04-09T09:15:51.927798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "method3_output = imputer.collate_prediction_outputs(predictions2)\n",
    "method3_output = torch_to_numpy(method3_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T09:15:33.716024Z",
     "iopub.status.busy": "2025-04-09T09:15:33.715718Z",
     "iopub.status.idle": "2025-04-09T09:15:33.733745Z",
     "shell.execute_reply": "2025-04-09T09:15:33.732818Z",
     "shell.execute_reply.started": "2025-04-09T09:15:33.716001Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xử lý kết quả dự đoán...\n",
      "Hello world\n",
      "Thông tin về kết quả dự đoán:\n",
      "- Kích thước y_hat: (2112, 14, 26, 7)\n"
     ]
    }
   ],
   "source": [
    "# Xử lý kết quả dự đoán để tạo DataFrame imputed\n",
    "print(\"Xử lý kết quả dự đoán...\")\n",
    "\n",
    "if True:\n",
    "    # Hàm để kết hợp kết quả từ các batch\n",
    "    def collate_prediction_outputs(outputs):\n",
    "        print(\"Hello world\")\n",
    "        processed_res = dict()\n",
    "        keys = set()\n",
    "        # Lặp qua kết quả từng batch\n",
    "        for res in outputs:\n",
    "            for k, v in res.items():\n",
    "                if k in keys:\n",
    "                    processed_res[k].append(v)\n",
    "                else:\n",
    "                    processed_res[k] = [v]\n",
    "                keys.add(k)\n",
    "        # Nối kết quả\n",
    "        for k, v in processed_res.items():\n",
    "            if all(torch.is_tensor(x) for x in v):\n",
    "                processed_res[k] = torch.cat(v, 0)\n",
    "        return processed_res\n",
    "    \n",
    "    # Kết hợp kết quả từ các batch\n",
    "    output = collate_prediction_outputs(predictions)\n",
    "    output = torch_to_numpy(output)\n",
    "    \n",
    "    print(\"Thông tin về kết quả dự đoán:\")\n",
    "    print(f\"- Kích thước y_hat: {output['y_hat'].shape}\")\n",
    "    \n",
    "    # Nếu có dữ liệu thực tế, tính metrics\n",
    "    if 'y' in output and output['y'] is not None:\n",
    "        if 'mask' in output and output['mask'] is not None:\n",
    "            mask = output['mask']\n",
    "            print(f\"- Số điểm có dữ liệu (mask=True): {mask.sum()}\")\n",
    "            \n",
    "            # Tính metrics trên dữ liệu đã biết\n",
    "            print(\"\\nMetrics trên dữ liệu đã biết:\")\n",
    "            print(f\"- MAE: {numpy_metrics.mae(output['y_hat'], output['y'], mask)}\")\n",
    "            print(f\"- MSE: {numpy_metrics.mse(output['y_hat'], output['y'], mask)}\")\n",
    "            print(f\"- RMSE: {numpy_metrics.rmse(output['y_hat'], output['y'], mask)}\")\n",
    "else:\n",
    "    print(\"Không có kết quả dự đoán!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T09:16:29.273562Z",
     "iopub.status.busy": "2025-04-09T09:16:29.273221Z",
     "iopub.status.idle": "2025-04-09T09:17:38.959897Z",
     "shell.execute_reply": "2025-04-09T09:17:38.958985Z",
     "shell.execute_reply.started": "2025-04-09T09:16:29.273537Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tạo DataFrame với giá trị đã được imputed (phiên bản cải tiến)...\n",
      "Tổng số giá trị bị thiếu: 149301\n",
      "Kích thước tensor dự đoán: (2112, 14, 26, 7)\n",
      "Số hàng trong DataFrame: 2183\n",
      "Số cột trong DataFrame: 182\n",
      "Cấu trúc index của cột: <class 'pandas.core.indexes.multi.MultiIndex'>\n",
      "Xử lý tensor 4D...\n",
      "Kích thước sau khi lấy middle time step: (2112, 26, 7)\n",
      "Xử lý MultiIndex columns...\n",
      "Số node phát hiện: 26\n",
      "Số feature phát hiện: 7\n",
      "Đang điền giá trị vào các vị trí bị thiếu...\n",
      "Đã điền 145106/149301 giá trị bị thiếu.\n",
      "Số lượng giá trị còn thiếu sau khi impute: 4195\n",
      "Phần trăm giá trị còn thiếu: 1.06%\n",
      "Đã lưu DataFrame đã được imputed vào file 'atmospheric_imputed.csv'\n",
      "\n",
      "Một số ví dụ về giá trị đã được điền:\n",
      "ID                              5                    \n",
      "satellite_based_factors       AAI     CLOUD        CO\n",
      "date                                                 \n",
      "2019-01-01              -1.112399  1.000000  0.044902\n",
      "2019-01-02              -0.346883  1.000000  0.043722\n",
      "2019-01-03              -0.590766  1.000000  0.049522\n",
      "2019-01-04              -0.074776  0.810048  0.049772\n",
      "2019-01-05              -0.680256  1.000000  0.053550\n",
      "\n",
      "Tỷ lệ giá trị còn thiếu theo từng node:\n",
      "Node 5: 152 giá trị thiếu (0.99%)\n",
      "Node 19: 162 giá trị thiếu (1.06%)\n",
      "Node 51: 154 giá trị thiếu (1.01%)\n",
      "Node 52: 161 giá trị thiếu (1.05%)\n",
      "Node 53: 161 giá trị thiếu (1.05%)\n",
      "Node 54: 160 giá trị thiếu (1.05%)\n",
      "Node 60: 169 giá trị thiếu (1.11%)\n",
      "Node 62: 157 giá trị thiếu (1.03%)\n",
      "Node 66: 155 giá trị thiếu (1.01%)\n",
      "Node 71: 164 giá trị thiếu (1.07%)\n",
      "Node 79: 158 giá trị thiếu (1.03%)\n",
      "Node 155: 157 giá trị thiếu (1.03%)\n",
      "Node 156: 161 giá trị thiếu (1.05%)\n",
      "Node 157: 162 giá trị thiếu (1.06%)\n",
      "Node 158: 168 giá trị thiếu (1.10%)\n",
      "Node 159: 161 giá trị thiếu (1.05%)\n",
      "Node 160: 156 giá trị thiếu (1.02%)\n",
      "Node 161: 170 giá trị thiếu (1.11%)\n",
      "Node 162: 162 giá trị thiếu (1.06%)\n",
      "Node 163: 164 giá trị thiếu (1.07%)\n",
      "Node 169: 161 giá trị thiếu (1.05%)\n",
      "Node 172: 153 giá trị thiếu (1.00%)\n",
      "Node 173: 160 giá trị thiếu (1.05%)\n",
      "Node 175: 170 giá trị thiếu (1.11%)\n",
      "Node 195: 185 giá trị thiếu (1.21%)\n",
      "Node 300: 152 giá trị thiếu (0.99%)\n"
     ]
    }
   ],
   "source": [
    "# Cải tiến hàm điền giá trị vào DataFrame\n",
    "print(\"Đang tạo DataFrame với giá trị đã được imputed (phiên bản cải tiến)...\")\n",
    "\n",
    "if 'output' in locals() and 'y_hat' in output:\n",
    "    # Tạo bản sao của DataFrame gốc\n",
    "    imputed_df = pivot_df.copy()\n",
    "    \n",
    "    # Xác định vị trí các giá trị bị thiếu\n",
    "    missing_mask = imputed_df.isna()\n",
    "    num_missing = missing_mask.sum().sum()\n",
    "    print(f\"Tổng số giá trị bị thiếu: {num_missing}\")\n",
    "    \n",
    "    try:\n",
    "        # Phân tích kích thước dự đoán và cấu trúc DataFrame\n",
    "        predictions_shape = output['y_hat'].shape\n",
    "        print(f\"Kích thước tensor dự đoán: {predictions_shape}\")\n",
    "        print(f\"Số hàng trong DataFrame: {len(imputed_df)}\")\n",
    "        print(f\"Số cột trong DataFrame: {len(imputed_df.columns)}\")\n",
    "        \n",
    "        # Kiểm tra cấu trúc index của các cột\n",
    "        print(f\"Cấu trúc index của cột: {type(imputed_df.columns)}\")\n",
    "        \n",
    "        # Xử lý kết quả dự đoán để khớp với định dạng của DataFrame\n",
    "        if len(predictions_shape) == 4:  # [samples, window, nodes, features]\n",
    "            print(\"Xử lý tensor 4D...\")\n",
    "            # Lấy giá trị ở middle time step\n",
    "            middle_step = predictions_shape[1] // 2\n",
    "            predictions = output['y_hat'][:, middle_step, :, :]\n",
    "            print(f\"Kích thước sau khi lấy middle time step: {predictions.shape}\")\n",
    "        elif len(predictions_shape) == 3:  # [window, nodes, features] hoặc [samples, nodes, features]\n",
    "            print(\"Xử lý tensor 3D...\")\n",
    "            if predictions_shape[0] > len(imputed_df):\n",
    "                # Trường hợp này là [samples, nodes, features]\n",
    "                predictions = output['y_hat']\n",
    "            else:\n",
    "                # Trường hợp này là [window, nodes, features]\n",
    "                middle_step = predictions_shape[0] // 2\n",
    "                predictions = output['y_hat'][middle_step, :, :]\n",
    "            print(f\"Kích thước sau khi xử lý: {predictions.shape}\")\n",
    "        else:\n",
    "            predictions = output['y_hat']\n",
    "            print(f\"Sử dụng tensor với kích thước: {predictions.shape}\")\n",
    "        \n",
    "        # Tạo mapping từ node và feature index sang DataFrame columns\n",
    "        column_map = {}\n",
    "        node_ids = []\n",
    "        feature_ids = []\n",
    "        \n",
    "        # Xác định tất cả các node và feature từ MultiIndex\n",
    "        try:\n",
    "            # Trường hợp MultiIndex (ID, feature)\n",
    "            if isinstance(imputed_df.columns, pd.MultiIndex):\n",
    "                print(\"Xử lý MultiIndex columns...\")\n",
    "                for i, (node, feature) in enumerate(imputed_df.columns):\n",
    "                    if node not in node_ids:\n",
    "                        node_ids.append(node)\n",
    "                    if feature not in feature_ids:\n",
    "                        feature_ids.append(feature)\n",
    "                    column_map[(node_ids.index(node), feature_ids.index(feature))] = i\n",
    "            else:\n",
    "                # Trường hợp Index đơn giản\n",
    "                print(\"Xử lý Index đơn giản...\")\n",
    "                for i, col in enumerate(imputed_df.columns):\n",
    "                    column_map[i] = i\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi phân tích cấu trúc cột: {e}\")\n",
    "            # Tạo mapping đơn giản dựa trên chỉ số\n",
    "            for i in range(len(imputed_df.columns)):\n",
    "                column_map[i] = i\n",
    "        \n",
    "        print(f\"Số node phát hiện: {len(node_ids)}\")\n",
    "        print(f\"Số feature phát hiện: {len(feature_ids)}\")\n",
    "        \n",
    "        # Điền giá trị thiếu trong DataFrame\n",
    "        print(\"Đang điền giá trị vào các vị trí bị thiếu...\")\n",
    "        \n",
    "        # Đếm số lượng giá trị đã được điền\n",
    "        filled_count = 0\n",
    "        skipped_count = 0\n",
    "        \n",
    "        # Phương pháp 1: Điền trực tiếp dùng mapping\n",
    "        if isinstance(imputed_df.columns, pd.MultiIndex):\n",
    "            # Duyệt qua từng ngày trong dữ liệu\n",
    "            for date_idx, date in enumerate(imputed_df.index):\n",
    "                if date_idx < predictions.shape[0]:\n",
    "                    # Duyệt qua từng node và feature\n",
    "                    for node_idx, node_id in enumerate(node_ids):\n",
    "                        if node_idx < predictions.shape[1]:\n",
    "                            for feat_idx, feat in enumerate(feature_ids):\n",
    "                                if feat_idx < predictions.shape[2]:\n",
    "                                    try:\n",
    "                                        # Xây dựng cột MultiIndex\n",
    "                                        col = (node_id, feat)\n",
    "                                        if col in imputed_df.columns and missing_mask.loc[date, col]:\n",
    "                                            # Điền giá trị dự đoán\n",
    "                                            imputed_df.loc[date, col] = predictions[date_idx, node_idx, feat_idx]\n",
    "                                            filled_count += 1\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Lỗi khi điền giá trị cho ngày {date}, node {node_id}, feature {feat}: {e}\")\n",
    "                                        skipped_count += 1\n",
    "        else:\n",
    "            # Phương pháp 2: Điền trực tiếp theo chỉ số đơn giản\n",
    "            dates = imputed_df.index.tolist()\n",
    "            for date_idx, date in enumerate(dates):\n",
    "                if date_idx < predictions.shape[0]:\n",
    "                    for col_idx, col in enumerate(imputed_df.columns):\n",
    "                        if missing_mask.loc[date, col]:\n",
    "                            node_idx = col_idx // imputation_dataset.n_channels\n",
    "                            feat_idx = col_idx % imputation_dataset.n_channels\n",
    "                            \n",
    "                            if node_idx < predictions.shape[1] and feat_idx < predictions.shape[2]:\n",
    "                                try:\n",
    "                                    # Điền giá trị dự đoán\n",
    "                                    imputed_df.loc[date, col] = predictions[date_idx, node_idx, feat_idx]\n",
    "                                    filled_count += 1\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Lỗi khi điền giá trị đơn giản cho {date}, cột {col}: {e}\")\n",
    "                                    skipped_count += 1\n",
    "        \n",
    "        print(f\"Đã điền {filled_count}/{num_missing} giá trị bị thiếu.\")\n",
    "        if skipped_count > 0:\n",
    "            print(f\"Đã bỏ qua {skipped_count} giá trị do lỗi.\")\n",
    "        \n",
    "        # Kiểm tra lại số lượng missing sau khi impute\n",
    "        remaining_missing = imputed_df.isna().sum().sum()\n",
    "        print(f\"Số lượng giá trị còn thiếu sau khi impute: {remaining_missing}\")\n",
    "        missing_pct = remaining_missing / imputed_df.size * 100\n",
    "        print(f\"Phần trăm giá trị còn thiếu: {missing_pct:.2f}%\")\n",
    "        \n",
    "        # Nếu vẫn còn nhiều giá trị thiếu, thử phương pháp khác\n",
    "        if remaining_missing > 0.3 * num_missing:\n",
    "            print(\"\\nVẫn còn nhiều giá trị thiếu, thử phương pháp khác...\")\n",
    "            \n",
    "            # Phương pháp 3: Thử điền giá trị bằng cách reshape tensor\n",
    "            try:\n",
    "                # Reshape predictions để phù hợp với DataFrame\n",
    "                flat_predictions = predictions.reshape(predictions.shape[0], -1)\n",
    "                print(f\"Kích thước tensor sau khi reshape: {flat_predictions.shape}\")\n",
    "                \n",
    "                # Kiểm tra từng hàng và thử điền giá trị thiếu\n",
    "                for date_idx, date in enumerate(imputed_df.index):\n",
    "                    if date_idx < flat_predictions.shape[0]:\n",
    "                        for col_idx, col in enumerate(imputed_df.columns):\n",
    "                            if missing_mask.loc[date, col] and col_idx < flat_predictions.shape[1]:\n",
    "                                imputed_df.loc[date, col] = flat_predictions[date_idx, col_idx]\n",
    "                \n",
    "                # Kiểm tra lại sau khi thử phương pháp mới\n",
    "                remaining_missing_new = imputed_df.isna().sum().sum()\n",
    "                improved = num_missing - remaining_missing_new\n",
    "                print(f\"Phương pháp mới đã điền thêm được {improved} giá trị.\")\n",
    "                print(f\"Số lượng giá trị còn thiếu: {remaining_missing_new}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi khi thử phương pháp mới: {e}\")\n",
    "        \n",
    "        # Lưu DataFrame đã được imputed\n",
    "        imputed_df.to_csv('atmospheric_imputed.csv')\n",
    "        print(\"Đã lưu DataFrame đã được imputed vào file 'atmospheric_imputed.csv'\")\n",
    "        \n",
    "        # Hiển thị một số ví dụ về giá trị đã được điền\n",
    "        print(\"\\nMột số ví dụ về giá trị đã được điền:\")\n",
    "        sample_cols = list(imputed_df.columns[:3])\n",
    "        sample_rows = imputed_df.index[:5]\n",
    "        print(imputed_df.loc[sample_rows, sample_cols])\n",
    "        \n",
    "        # Kiểm tra tỷ lệ missing của từng node\n",
    "        print(\"\\nTỷ lệ giá trị còn thiếu theo từng node:\")\n",
    "        try:\n",
    "            if isinstance(imputed_df.columns, pd.MultiIndex):\n",
    "                node_missing = {}\n",
    "                for node in node_ids:\n",
    "                    node_cols = [col for col in imputed_df.columns if col[0] == node]\n",
    "                    missing_count = imputed_df[node_cols].isna().sum().sum()\n",
    "                    total_count = len(node_cols) * len(imputed_df)\n",
    "                    node_missing[node] = (missing_count, missing_count/total_count*100)\n",
    "                \n",
    "                for node, (count, pct) in node_missing.items():\n",
    "                    print(f\"Node {node}: {count} giá trị thiếu ({pct:.2f}%)\")\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi phân tích missing theo node: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi điền giá trị vào DataFrame: {e}\")\n",
    "else:\n",
    "    print(\"Không có dữ liệu dự đoán để tạo DataFrame imputed.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7079624,
     "sourceId": 11318507,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "spatiotemporal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
