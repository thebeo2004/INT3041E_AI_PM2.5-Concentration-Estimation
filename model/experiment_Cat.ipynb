{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b809522f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'module'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "import sklearn.metrics as metrics\n",
    "import pickle\n",
    "from time_series_split import *\n",
    "print(type(metrics))\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76bd1ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_aqi(pm25):\n",
    "    ranges = [\n",
    "        (0.0, 12.0, 0, 50),\n",
    "        (12.1, 35.4, 51, 100),\n",
    "        (35.5, 55.4, 101, 150),\n",
    "        (55.5, 150.4, 151, 200),\n",
    "        (150.5, 250.4, 201, 300),\n",
    "        (250.5, 500.0, 301, 500),\n",
    "    ]\n",
    "    for c_low, c_high, aqi_low, aqi_high in ranges:\n",
    "        if c_low <= pm25 <= c_high:\n",
    "            return round((aqi_high - aqi_low) / (c_high - c_low) * (pm25 - c_low) + aqi_low)\n",
    "    return 500  # default náº¿u vÆ°á»£t ngÆ°á»¡ng\n",
    "\n",
    "def aqi_class(aqi):\n",
    "    if aqi <= 50: return 0\n",
    "    elif aqi <= 100: return 1\n",
    "    elif aqi <= 150: return 2\n",
    "    elif aqi <= 200: return 3\n",
    "    elif aqi <= 300: return 4\n",
    "    else: return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe7467e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of folds: 3\n"
     ]
    }
   ],
   "source": [
    "combined_data = pd.read_csv('/home/thu/INT3041E_AI_PM2.5-Concentration-Estimation/data/add_AQI.csv')\n",
    "combined_data['AQI'] = combined_data['pm25'].apply(calculate_aqi)\n",
    "combined_data['AQI_Class'] = combined_data['AQI'].apply(aqi_class)\n",
    "folds = split_consolidated_data()\n",
    "print(f\"Number of folds: {len(folds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'iterations': 500,  # Tuning iterations for CatBoost\n",
    "    'depth': 8,\n",
    "    'learning_rate': 0.3,\n",
    "    \"l2_leaf_reg\": 3,\n",
    "    'loss_function': 'MultiClass',\n",
    "    'custom_metric': ['AUC'],\n",
    "    'cat_features': []  # List of categorical features if any\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b19f3f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biáº¿n lÆ°u nhÃ£n tháº­t vÃ  dá»± Ä‘oÃ¡n trÃªn toÃ n bá»™ test sets\n",
    "all_y_true = []\n",
    "all_y_pred = []\n",
    "val_accuracies = []\n",
    "test_accuracies = []\n",
    "test_classification_reports = []\n",
    "\n",
    "best_val_accuracy = 0\n",
    "best_model = None\n",
    "all_target_names = ['Good', 'Moderate', 'Unhealthy for Sensitive', 'Unhealthy', 'Very Unhealthy', 'Hazardous']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d9969c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Fold 1/3\n",
      "0:\tlearn: 1.5042845\ttotal: 266ms\tremaining: 2m 12s\n",
      "100:\tlearn: 0.2894852\ttotal: 16.8s\tremaining: 1m 6s\n",
      "200:\tlearn: 0.1653375\ttotal: 30s\tremaining: 44.6s\n",
      "300:\tlearn: 0.1114797\ttotal: 42.8s\tremaining: 28.3s\n",
      "400:\tlearn: 0.0796780\ttotal: 57.1s\tremaining: 14.1s\n",
      "499:\tlearn: 0.0602929\ttotal: 1m 10s\tremaining: 0us\n",
      "Train Accuracy: 0.9987 | Validation Accuracy: 0.6885 | Test Accuracy: 0.4251\n",
      "\n",
      "Processing Fold 2/3\n",
      "0:\tlearn: 1.5001792\ttotal: 173ms\tremaining: 1m 26s\n",
      "100:\tlearn: 0.2828136\ttotal: 12.5s\tremaining: 49.5s\n",
      "200:\tlearn: 0.1663182\ttotal: 26.3s\tremaining: 39.1s\n",
      "300:\tlearn: 0.1126487\ttotal: 40.5s\tremaining: 26.8s\n",
      "400:\tlearn: 0.0797486\ttotal: 57.8s\tremaining: 14.3s\n",
      "499:\tlearn: 0.0610071\ttotal: 1m 12s\tremaining: 0us\n",
      "Train Accuracy: 0.9986 | Validation Accuracy: 0.4709 | Test Accuracy: 0.4967\n",
      "\n",
      "Processing Fold 3/3\n",
      "0:\tlearn: 1.5019723\ttotal: 122ms\tremaining: 1m\n",
      "100:\tlearn: 0.2933683\ttotal: 16.1s\tremaining: 1m 3s\n",
      "200:\tlearn: 0.1766715\ttotal: 32.6s\tremaining: 48.5s\n",
      "300:\tlearn: 0.1193551\ttotal: 46.8s\tremaining: 30.9s\n",
      "400:\tlearn: 0.0855103\ttotal: 1m 1s\tremaining: 15.3s\n",
      "499:\tlearn: 0.0653958\ttotal: 1m 16s\tremaining: 0us\n",
      "Train Accuracy: 0.9980 | Validation Accuracy: 0.5163 | Test Accuracy: 0.4810\n"
     ]
    }
   ],
   "source": [
    "for i, fold in enumerate(folds):\n",
    "    print(f\"\\nProcessing Fold {i+1}/{len(folds)}\")\n",
    "\n",
    "    train_data = fold['train']\n",
    "    val_data = fold['validation']\n",
    "    test_data = fold['test']\n",
    "\n",
    "    feature_columns = train_data.columns[3:-2]\n",
    "    X_train = train_data[feature_columns]\n",
    "    y_train = train_data['AQI_Class']\n",
    "    X_val = val_data[feature_columns]\n",
    "    y_val = val_data['AQI_Class']\n",
    "    X_test = test_data[feature_columns]\n",
    "    y_test = test_data['AQI_Class']\n",
    "    \n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    clf = CatBoostClassifier(**params, random_seed=43)\n",
    "    clf.fit(X_train, y_train, verbose=100)\n",
    "\n",
    "    train_acc = clf.score(X_train, y_train)\n",
    "    val_acc = clf.score(X_val, y_val)\n",
    "    test_acc = clf.score(X_test, y_test)\n",
    "\n",
    "    print(f\"Train Accuracy: {train_acc:.4f} | Validation Accuracy: {val_acc:.4f} | Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    val_accuracies.append(val_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "    if val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = val_acc\n",
    "        best_model = clf\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # LÆ°u nhÃ£n tháº­t vÃ  nhÃ£n dá»± Ä‘oÃ¡n\n",
    "    all_y_true.extend(y_test.tolist())\n",
    "    all_y_pred.extend(y_pred.tolist())\n",
    "\n",
    "    report = metrics.classification_report(\n",
    "        y_test, y_pred, target_names=all_target_names, labels=[0, 1, 2, 3, 4, 5], output_dict=True, zero_division=1\n",
    "    )\n",
    "    test_classification_reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9734e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Validation Accuracy: 0.6106\n",
      "Average Test Accuracy: 0.4506\n"
     ]
    }
   ],
   "source": [
    "mean_val_accuracy = np.mean(val_accuracies)\n",
    "mean_test_accuracy = np.mean(test_accuracies)\n",
    "print(f\"\\nAverage Validation Accuracy: {mean_val_accuracy:.4f}\")\n",
    "print(f\"Average Test Accuracy: {mean_test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a408927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BÃ¡o cÃ¡o trung bÃ¬nh tá»«ng lá»›p\n",
    "avg_report = {}\n",
    "for label in all_target_names:\n",
    "    precisions = [r[label]['precision'] for r in test_classification_reports if label in r]\n",
    "    recalls = [r[label]['recall'] for r in test_classification_reports if label in r]\n",
    "    f1_scores = [r[label]['f1-score'] for r in test_classification_reports if label in r]\n",
    "    supports = [r[label]['support'] for r in test_classification_reports if label in r]\n",
    "\n",
    "    avg_report[label] = {\n",
    "        'precision': np.mean(precisions),\n",
    "        'recall': np.mean(recalls),\n",
    "        'f1-score': np.mean(f1_scores),\n",
    "        'support': sum(supports),\n",
    "        'num_folds': len(precisions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a92c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted avg\n",
    "avg_report['weighted avg'] = {\n",
    "    'precision': np.mean([r['weighted avg']['precision'] for r in test_classification_reports]),\n",
    "    'recall': np.mean([r['weighted avg']['recall'] for r in test_classification_reports]),\n",
    "    'f1-score': np.mean([r['weighted avg']['f1-score'] for r in test_classification_reports]),\n",
    "    'support': sum([r['weighted avg']['support'] for r in test_classification_reports])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d97dd95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‹ Average Classification Report:\n",
      "Good:\n",
      "  Precision: 0.5879\n",
      "  Recall: 0.3771\n",
      "  F1-score: 0.4590\n",
      "  Support: 436\n",
      "  Number of folds with this class: 5\n",
      "Hazardous:\n",
      "  Precision: 0.6000\n",
      "  Recall: 0.4000\n",
      "  F1-score: 0.2000\n",
      "  Support: 3\n",
      "  Number of folds with this class: 5\n",
      "Moderate:\n",
      "  Precision: 0.4606\n",
      "  Recall: 0.6406\n",
      "  F1-score: 0.5265\n",
      "  Support: 614\n",
      "  Number of folds with this class: 5\n",
      "Unhealthy:\n",
      "  Precision: 0.3784\n",
      "  Recall: 0.3586\n",
      "  F1-score: 0.3598\n",
      "  Support: 283\n",
      "  Number of folds with this class: 5\n",
      "Unhealthy for Sensitive:\n",
      "  Precision: 0.1894\n",
      "  Recall: 0.0899\n",
      "  F1-score: 0.1177\n",
      "  Support: 263\n",
      "  Number of folds with this class: 5\n",
      "Very Unhealthy:\n",
      "  Precision: 0.6000\n",
      "  Recall: 0.6000\n",
      "  F1-score: 0.6000\n",
      "  Support: 4\n",
      "  Number of folds with this class: 5\n",
      "weighted avg:\n",
      "  Precision: 0.4580\n",
      "  Recall: 0.4506\n",
      "  F1-score: 0.4325\n",
      "  Support: 1603\n"
     ]
    }
   ],
   "source": [
    "# In ra report trung bÃ¬nh\n",
    "print(\"\\nðŸ“‹ Average Classification Report:\")\n",
    "for label in sorted(avg_report.keys(), key=lambda x: x if x != 'weighted avg' else 'zzz'):\n",
    "    print(f\"{label}:\")\n",
    "    print(f\"  Precision: {avg_report[label]['precision']:.4f}\")\n",
    "    print(f\"  Recall: {avg_report[label]['recall']:.4f}\")\n",
    "    print(f\"  F1-score: {avg_report[label]['f1-score']:.4f}\")\n",
    "    print(f\"  Support: {avg_report[label]['support']:.0f}\")\n",
    "    if label != 'weighted avg':\n",
    "        print(f\"  Number of folds with this class: {avg_report[label]['num_folds']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbb83e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Overall Classification Report for ALL Samples\n",
      "============================================================\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                   Good       0.63      0.40      0.49       436\n",
      "               Moderate       0.44      0.64      0.52       614\n",
      "Unhealthy for Sensitive       0.17      0.09      0.12       263\n",
      "              Unhealthy       0.44      0.45      0.45       283\n",
      "         Very Unhealthy       0.00      0.00      0.00         4\n",
      "              Hazardous       0.00      0.00      0.00         3\n",
      "\n",
      "               accuracy                           0.45      1603\n",
      "              macro avg       0.28      0.26      0.26      1603\n",
      "           weighted avg       0.45      0.45      0.43      1603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TÃ­nh vÃ  in classification report tá»•ng táº¥t cáº£ sample\n",
    "final_report = metrics.classification_report(\n",
    "    all_y_true, all_y_pred,\n",
    "    target_names=all_target_names,\n",
    "    labels=[0, 1, 2, 3, 4, 5]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Overall Classification Report for ALL Samples\")\n",
    "print(\"=\"*60)\n",
    "print(final_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfd8807e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1-score: 0.4326 | Total Samples: 1603\n"
     ]
    }
   ],
   "source": [
    "# BÃ¡o cÃ¡o dáº¡ng dict Ä‘á»ƒ trÃ­ch F1 tá»•ng thá»ƒ\n",
    "report_dict = metrics.classification_report(\n",
    "    all_y_true, all_y_pred,\n",
    "    target_names=all_target_names,\n",
    "    labels=[0,1,2,3,4,5],\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "overall_f1 = report_dict[\"weighted avg\"][\"f1-score\"]\n",
    "overall_support = report_dict[\"weighted avg\"][\"support\"]\n",
    "print(f\"Weighted F1-score: {overall_f1:.4f} | Total Samples: {int(overall_support)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b5163cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model saved as 'catboost-aqi-classifier.pkl'\n"
     ]
    }
   ],
   "source": [
    "# LÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t\n",
    "pickle.dump(best_model, open('metadata/checkpoint/catboost-aqi-classifier.pkl', 'wb'))\n",
    "print(\"\\nBest model saved as 'catboost-aqi-classifier.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a484d74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
